{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "import tensorflow as tf\n",
    "\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from fast_rcnn.config import cfg\n",
    "from fast_rcnn.test import im_detect\n",
    "from fast_rcnn.nms_wrapper import nms\n",
    "from utils.timer import Timer\n",
    "import numpy as np\n",
    "import os, sys, cv2\n",
    "import argparse\n",
    "from networks.factory import get_network\n",
    "\n",
    "CLASSES =('__background__', \n",
    "                            \"box\",\n",
    "                            \"gum\",\n",
    "                            \"marker\",\n",
    "                            \"pen\",\n",
    "                            \"postit\",\n",
    "                            \"scissors\",\n",
    "                            \"tape\",\n",
    "                            \"usb\"\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#CLASSES = ('__background__','person','bike','motorbike','car','bus')\n",
    "\n",
    "def vis_detections(im, class_name, dets,ax, thresh=0.5):\n",
    "    \"\"\"Draw detected bounding boxes.\"\"\"\n",
    "    inds = np.where(dets[:, -1] >= thresh)[0]\n",
    "    if len(inds) == 0:\n",
    "        return\n",
    "\n",
    "    for i in inds:\n",
    "        bbox = dets[i, :4]\n",
    "        score = dets[i, -1]\n",
    "\n",
    "        ax.add_patch(\n",
    "            plt.Rectangle((bbox[0], bbox[1]),\n",
    "                          bbox[2] - bbox[0],\n",
    "                          bbox[3] - bbox[1], fill=False,\n",
    "                          edgecolor='red', linewidth=3.5)\n",
    "            )\n",
    "        ax.text(bbox[0], bbox[1] - 2,\n",
    "                '{:s} {:.3f}'.format(class_name, score),\n",
    "                bbox=dict(facecolor='blue', alpha=0.5),\n",
    "                fontsize=14, color='white')\n",
    "\n",
    "    ax.set_title(('{} detections with '\n",
    "                  'p({} | box) >= {:.1f}').format(class_name, class_name,\n",
    "                                                  thresh),\n",
    "                  fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def demo(sess, net, image_name):\n",
    "    \"\"\"Detect object classes in an image using pre-computed object proposals.\"\"\"\n",
    "\n",
    "    # Load the demo image\n",
    "    im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n",
    "    #im_file = os.path.join('/home/corgi/Lab/label/pos_frame/ACCV/training/000001/',image_name)\n",
    "    im = cv2.imread(im_file)\n",
    "\n",
    "    # Detect all object classes and regress object bounds\n",
    "    timer = Timer()\n",
    "    timer.tic()\n",
    "    scores, boxes = im_detect(sess, net, im)\n",
    "    timer.toc()\n",
    "    print ('Detection took {:.3f}s for '\n",
    "           '{:d} object proposals').format(timer.total_time, boxes.shape[0])\n",
    "\n",
    "    # Visualize detections for each class\n",
    "    im = im[:, :, (2, 1, 0)]\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.imshow(im, aspect='equal')\n",
    "\n",
    "    CONF_THRESH = 0.8\n",
    "    NMS_THRESH = 0.3\n",
    "    for cls_ind, cls in enumerate(CLASSES[1:]):\n",
    "        cls_ind += 1 # because we skipped background\n",
    "        cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "        cls_scores = scores[:, cls_ind]\n",
    "        dets = np.hstack((cls_boxes,\n",
    "                          cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "        keep = nms(dets, NMS_THRESH)\n",
    "        dets = dets[keep, :]\n",
    "        vis_detections(im, cls, dets, ax, thresh=CONF_THRESH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg.TEST.HAS_RPN = True  # Use RPN for proposals\n",
    "gpu_id = 1\n",
    "demo_net = \"VGGnet_test\"\n",
    "model = \"/data/code/Faster-RCNN_TF/output/faster_rcnn_end2end/office_supplies/VGGnet_fast_rcnn_iter_200.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfg.DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# image_name = 'pedestrian_cars.jpg'\n",
    "# im_file = os.path.join(cfg.DATA_DIR, 'demo', image_name)\n",
    "im = cv2.imread(\"/data/code/Faster-RCNN_TF/data/office_supplies/images/11.jpg\")\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_conv/3x3/rpn_conv/3x3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_cls_score/rpn_cls_score:0\", shape=(?, ?, ?, 18), dtype=float32)\n",
      "Tensor(\"rpn_cls_prob:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"rpn_cls_prob_reshape:0\", shape=(?, ?, ?, 18), dtype=float32)\n",
      "Tensor(\"rpn_bbox_pred/rpn_bbox_pred:0\", shape=(?, ?, ?, 36), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rois:0\", shape=(?, 5), dtype=float32)\n",
      "[<tf.Tensor 'conv5_3/conv5_3:0' shape=(?, ?, ?, 512) dtype=float32>, <tf.Tensor 'rois:0' shape=(?, 5) dtype=float32>]\n",
      "Tensor(\"fc7/fc7:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "net = get_network(demo_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loaded network /data/code/Faster-RCNN_TF/output/faster_rcnn_end2end/office_supplies/VGGnet_fast_rcnn_iter_200.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, model)\n",
    "\n",
    "print('\\n\\nLoaded network {:s}'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 9)\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('cls_score', reuse=True):\n",
    "    print(tf.get_variable('weights').get_shape())\n",
    "    print(tf.get_variable('biases').get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = net.layers\n",
    "out_layers = {'cls_score', 'bbox_pred', 'roi-data'}\n",
    "out_dict = {}\n",
    "for layer in layers:\n",
    "    if layer in out_layers:\n",
    "        continue\n",
    "    allvsrs = tf.get_collection(tf.GraphKeys.VARIABLES, layer)\n",
    "    if len(allvsrs) > 0:\n",
    "        d={}\n",
    "        for variable in allvsrs:\n",
    "            d[variable.name.split('/')[1].split(':')[0]] = variable.eval(session=sess)\n",
    "        out_dict[layer] = d\n",
    "# with tf.variable_scope(, reuse=True):\n",
    "#     td = tf.get_variable('weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/tmp/trained_model.npy', 'w') as f:\n",
    "    np.save(f, out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "im_names = ['000456.jpg', '000542.jpg', '001150.jpg', '001763.jpg', '004545.jpg']\n",
    "#im_names = ['000456.jpg']\n",
    "for im_name in im_names:\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Demo for data/demo/{}'.format(im_name))\n",
    "    demo(sess, net, im_name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/data/robotics/raw_position_images/train_2' + '.tfrecords'\n",
    "\n",
    "example = tf.train.Example()\n",
    "pi = tf.python_io.tf_record_iterator(filename)\n",
    "example.ParseFromString(pi.next())\n",
    "\n",
    "dat = np.fromstring(example.features.feature[\"left_image\"].bytes_list.value[0], dtype=np.uint8)\n",
    "\n",
    "\n",
    "im = dat.reshape((480, 640, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores, boxes = im_detect(sess, net, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# im = im[:, :, (2, 1, 0)]\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(im, aspect='equal')\n",
    "\n",
    "CONF_THRESH = 0.04\n",
    "NMS_THRESH = 0.03\n",
    "for cls_ind, cls in enumerate(CLASSES[1:]):\n",
    "    cls_ind += 1 # because we skipped background\n",
    "    cls_boxes = boxes[:, 4*cls_ind:4*(cls_ind + 1)]\n",
    "    cls_scores = scores[:, cls_ind]\n",
    "    dets = np.hstack((cls_boxes,\n",
    "                      cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "    keep = nms(dets, NMS_THRESH)\n",
    "    dets = dets[keep, :]\n",
    "    print(keep)\n",
    "    vis_detections(im, cls, dets, ax, thresh=CONF_THRESH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dets = np.hstack((cls_boxes,\n",
    "                  cls_scores[:, np.newaxis])).astype(np.float32)\n",
    "keep = nms(dets, NMS_THRESH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(dets[:, -1] >= 0.04)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dets[keep, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_ind = 2\n",
    "boxes[:, 4*cls_ind:4*(cls_ind + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "ax.imshow(im)\n",
    "fig.canvas.mpl_connect( \"button_press_event\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x0, y0, x1, y_1) = linebuilder.x_0, linebuilder.y_0, linebuilder.x_press, linebuilder.y_press\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
